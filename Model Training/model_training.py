# Import necessary libraries for ML Long Short Term Memory Model
import yfinance as yf
import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

#Fetch the data from Yahoo Finance

#Define the stocks to train the model on
""" Add more stocks later.
It would be nice to train the model on 1-2k stocks across 
various sectors to build a more complete model
"""

tickers = ['AAPL']

#Download all the historical data for teh last 20 years for each of the stocks
data = yf.download(tickers, start='2004-01-01', end='2024-01-01', group_by='ticker' )


#Flatten the MultiIndex
data.columns =['_'.join(col) for col in data.columns]

#Build moving averages

for ticker in tickers:
    data[f'{ticker}_MA5'] = data[f'{ticker}_Adj Close'].rolling(window=5).mean()
    data[f'{ticker}_MA20'] = data[f'{ticker}_Adj Close'].rolling(window=20).mean()
    data[f'{ticker}_MA50'] = data[f'{ticker}_Adj Close'].rolling(window=50).mean()


#Remove Uneccesary Rows
data.dropna(inplace=True)

# Features: Adjusted Close, Volume, and Moving Averages
for ticker in tickers:
    data[f'{ticker}_return'] = data[f'{ticker}_Adj Close'].pct_change()  # daily returns
    data[f'{ticker}_Volume'] = data[f'{ticker}_Volume']  # Use Volume as a feature

# Drop any rows with NaN values generated by rolling or pct_change
data.dropna(inplace=True)

print(data)

def compute_rsi(data, window=14):
    delta = data.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

for ticker in tickers:
    data[f'{ticker}_RSI'] = compute_rsi(data[f'{ticker}_Adj Close'])

#Drop any extra rows created
data.dropna(inplace=True)

# Features and labels arrays
#Features are variables that are changed
#Labels are the percentace change
features = []
labels = []

# For each ticker, prepare the data
for ticker in tickers:
    ticker_data = data[[f'{ticker}_Adj Close', f'{ticker}_MA5', f'{ticker}_MA20', f'{ticker}_MA50', f'{ticker}_return', f'{ticker}_Volume'], f'{ticker}_RSI']
    
    #Calculate and Assign percentage change to labels as value.
    label = (data[f'{ticker}_Adj Close'].shift(-1) - data[f'{ticker}_Adj Close']) / data[f'{ticker}_Adj Close'] * 100
    
    # Drop rows where the shifted label is NaN
    ticker_data = ticker_data[:-1]
    label = label[:-1]

    features.append(ticker_data.values)
    labels.append(label.values)
#Delete unesseary values created in loop
data.dropna(inplace=True)


# Convert to numpy arrays
features = np.array(features)
labels = np.array(labels)

# Reshaping the features for LSTM
# Features should be in the shape (samples, time_steps, features)
features = features.reshape(features.shape[0], features.shape[1], features.shape[2])

#Flatten features and labels
features_flat = features.reshape(-1, features.shape[2])
labels_flat = labels.reshape(-1, 1)

#Split the data up for testing.
#Currently using a 20% testing set. This is subject to optimization.
X_train, X_test, y_train, y_test = train_test_split(features_flat, labels_flat, test_size=0.2, shuffle=False)

#Scale the data
scaler_x = MinMaxScaler(feature_range=(0,1))
scaler_y = MinMaxScaler(feature_range=(0,1))

# Scale the features and labels
#Features
X_train_scaled = scaler_x.fit_transform(X_train)
X_test_scaled = scaler_x.transform(X_test)
#Make teh Scale 3D to fit LSTM
X_train_scaled = np.expand_dims(X_train_scaled, axis=1)  # (samples, time_steps, features)
X_test_scaled = np.expand_dims(X_test_scaled, axis=1)

#Labels
y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

#Create the time sequence to train the data on the last # of days
def create_sequences(features, labels, time_steps):
    X, y = [], []
    for i in range(len(features) - time_steps):
        X.append(features[i:i + time_steps])  # Collect `time_steps` rows
        y.append(labels[i + time_steps])     # Predict the label at `time_steps` ahead
    return np.array(X), np.array(y)

# Define the number of time steps
time_steps = 30  # Adjust this to use more historical data -- Currently set for last 30 days

# Create sequences using the sliding window
X_train_scaled, y_train_scaled = create_sequences(X_train_scaled, y_train_scaled, time_steps)
X_test_scaled, y_test_scaled = create_sequences(X_test_scaled, y_test_scaled, time_steps)

#create_sequences creates an extra dimension in the 2 slot.
#Remove the extra dimension
X_train_scaled = np.squeeze(X_train_scaled, axis=2)
X_test_scaled = np.squeeze(X_test_scaled, axis=2)


# Define the Model
model = tf.keras.Sequential()

# Use Input Layer
model.add(tf.keras.layers.Input(shape=(time_steps, X_train_scaled.shape[2]))) #Flexible input layer for adaptable sequence time

# LSTM Layers
model.add(tf.keras.layers.LSTM(50, return_sequences=True))
model.add(tf.keras.layers.Dropout(0.2))

model.add(tf.keras.layers.LSTM(50, return_sequences=False))
model.add(tf.keras.layers.Dropout(0.2))

# Dense Layer: Final output prediction layer
model.add(tf.keras.layers.Dense(1))  # For predicting next day's percentage change

# Compile the Model
model.compile(optimizer='adam', loss='mean_squared_error')

#Create the model

#Alert that model training is commencing:
print("Commencing Model Training")

from tensorflow.keras.callbacks import EarlyStopping

# Define EarlyStopping Callback
early_stopping = EarlyStopping(
    monitor='val_loss',    # Monitors the validation loss
    patience=10,           # Stops training if no improvement after 10 epochs
    restore_best_weights=True  # Restores the weights of the best model during training
)

# Train the model with the callback
history = model.fit(
    X_train_scaled, 
    y_train_scaled, 
    epochs=50, 
    batch_size=32, 
    validation_data=(X_test_scaled, y_test_scaled), 
    callbacks=[early_stopping],
    verbose=1
)

#Evaluate the Model
test_loss = model.evaluate(X_test_scaled,y_test_scaled)
print(test_loss)

#Save the model
model.save('../Models/model.h5')
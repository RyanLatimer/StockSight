import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import pandas as pd
import functions as f
import yfinance as yf
import os
print(tf.__version__)

model = tf.keras.models.load_model('test_model.keras')

#Verify the model format
model.summary()

#Gather user input
user_ticker = input("Enter a valid stock ticker:  ")

#Download all the historical data for the last 20 years for the stock
data = yf.download(user_ticker, start='2004-01-01', end='2024-01-01', group_by='ticker' )

#Flatten the MultiIndex
data.columns = ['_'.join(col) for col in data.columns]

#Verify the columns after flattening
print(f"Columns after flattening: {data.columns}")

# Build moving averages
data[f'{user_ticker}_MA5'] = data[f'{user_ticker}_Adj Close'].rolling(window=5).mean()
data[f'{user_ticker}_MA20'] = data[f'{user_ticker}_Adj Close'].rolling(window=20).mean()
data[f'{user_ticker}_MA50'] = data[f'{user_ticker}_Adj Close'].rolling(window=50).mean()

# Remove NaN rows generated by rolling
data.dropna(inplace=True)

# Add features like return and volume
data[f'{user_ticker}_return'] = data[f'{user_ticker}_Adj Close'].pct_change()  # daily returns
data[f'{user_ticker}_Volume'] = data[f'{user_ticker}_Volume']

# Drop any NaN rows created by pct_change
data.dropna(inplace=True)

# Compute RSI
def compute_rsi(data, window=14):
    delta = data.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

data[f'{user_ticker}_RSI'] = compute_rsi(data[f'{user_ticker}_Adj Close'])

# Drop any extra rows created
data.dropna(inplace=True)

# Add Bollinger Bands
def bollinger_bands(data, ticker, window=20):
    rolling_mean = data[f'{ticker}_Adj Close'].rolling(window=window).mean()
    rolling_std = data[f'{ticker}_Adj Close'].rolling(window=window).std()
    bb_upper = rolling_mean + (rolling_std * 2)
    bb_lower = rolling_mean - (rolling_std * 2)
    data[f'{ticker}_BB_Upper'] = bb_upper
    data[f'{ticker}_BB_Lower'] = bb_lower

bollinger_bands(data, user_ticker)

# Add Stochastic Oscillator
def stochastic_oscillator(data, ticker, window=14):
    low_min = data[f'{ticker}_Low'].rolling(window=window).min()
    high_max = data[f'{ticker}_High'].rolling(window=window).max()
    stoch_k = 100 * (data[f'{ticker}_Adj Close'] - low_min) / (high_max - low_min)
    stoch_d = stoch_k.rolling(window=3).mean()
    return stoch_k, stoch_d

data[f'{user_ticker}_StochK'], data[f'{user_ticker}_StochD'] = stochastic_oscillator(data, user_ticker)
data.dropna(inplace=True)

# Add On-Balance Volume (OBV)
def on_balance_volume(data, ticker):
    obv = [0]
    for i in range(1, len(data)):
        if data[f'{ticker}_Adj Close'].iloc[i] > data[f'{ticker}_Adj Close'].iloc[i - 1]:
            obv.append(obv[-1] + data[f'{ticker}_Volume'].iloc[i])
        elif data[f'{ticker}_Adj Close'].iloc[i] < data[f'{ticker}_Adj Close'].iloc[i - 1]:
            obv.append(obv[-1] - data[f'{ticker}_Volume'].iloc[i])
        else:
            obv.append(obv[-1])  # If the close is the same as previous, OBV doesn't change
    return obv

data[f'{user_ticker}_OBV'] = on_balance_volume(data, user_ticker)

# Add Chaikin Money Flow (CMF) indicator
def chaikin_money_flow(data, ticker, window=20):
    # Calculate the Accumulation/Distribution line
    adl = (2 * data[f'{ticker}_Adj Close'] - data[f'{ticker}_Low'] - data[f'{ticker}_High']) / (data[f'{ticker}_High'] - data[f'{ticker}_Low'])
    adl = adl * data[f'{ticker}_Volume']
    
    # Calculate the CMF
    cmf = adl.rolling(window=window).sum() / data[f'{ticker}_Volume'].rolling(window=window).sum()
    data[f'{ticker}_CMF'] = cmf

# Call the function to calculate CMF for the user_ticker
chaikin_money_flow(data, user_ticker)

# Drop any NaN values after all calculations
data.dropna(inplace=True)

# Create the Scaler
scaler_x = MinMaxScaler(feature_range=(0, 1))

print(data.columns)
# Convert to Numpy array
relevant_features = [f'{user_ticker}_Adj Close', f'{user_ticker}_MA5', f'{user_ticker}_MA20', f'{user_ticker}_MA50', f'{user_ticker}_return', f'{user_ticker}_Volume', f'{user_ticker}_RSI', f'{user_ticker}_BB_Upper', f'{user_ticker}_BB_Lower', f'{user_ticker}_StochK', f'{user_ticker}_StochD', f'{user_ticker}_OBV', f'{user_ticker}_CMF']
data_array = data[relevant_features].values

# Create sequences from the data array
time_steps = 30
def create_sequences(data, time_steps):
    sequences = []
    for i in range(len(data) - time_steps + 1):
        sequences.append(data[i:i + time_steps])
    return np.array(sequences)

data_sequences = create_sequences(data_array, time_steps)

# Scale the entire data
scaled_data = scaler_x.fit_transform(data_array)

# Then create scaled sequences
scaled_sequences = create_sequences(scaled_data, time_steps)

# Make predictions
predictions = model.predict(scaled_sequences)

# If you scaled the labels during training, inverse-transform the predictions
predictions_unscaled = scaler_x.inverse_transform(predictions)

# Match predictions with dates
predicted_dates = data.index[time_steps - 1:]
results = pd.DataFrame({'Date': predicted_dates, 'Prediction': predictions.flatten()})
results.reset_index(drop=True, inplace=True)

# Display results
print(results)
